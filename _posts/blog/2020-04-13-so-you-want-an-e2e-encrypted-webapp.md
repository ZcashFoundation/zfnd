---
layout: post
title: "So You Want to Build an End-to-End Encrypted Web App", aka, Musings on Long-term Identity
excerpt: "The software security model of the web does not lend itself to long term identities."
categories: blog
tags: [cryptography, web development, software security]
date: 2020-04-13
author: dconnolly
---


So it would be really nice if we could do end-to-end encrypted video calling, like we do between devices like a desktop app or a mobile app, but in the browser. A web app is not the same type of app where you can install a version on your desktop or on your iPhone or your Android phone. A web app is served from a web server and is usually (but not always) completely reloaded, served, and reprocessed by the browser every time you load the page. There's some caching involved, but usually every time you load the page, you are fetching the software to run your web app from an edge server (and not necessarily a server controlled by the people who wrote the app), downloading it and running that software inside the browser sandbox. This affects how securely we can keep data that is stored in or controlled by the browser app versus how securely we can keep data that is stored in a mobile app or a desktop app. 

In a desktop app or mobile app, usually what happens on most modern OSs is there is a developer who has a signing key that is attested to by some signing authority, something like the Apple store or the Google Play store. They sign the package that you download. That key that they sign it with has been attested to by the signing authority, which your OS trusts: Android trusts the Google Play Store, iOS trusts the App Store / Apple,  Windows trusts Microsoft, etc. So when you install the package, however you get it onto your device, your OS checks the signature on it. The OS checks that the developer that supposedly signed it actually signed it, and it checks that those keys were attested to by the signing authority that you already trust, because the keys that you need to trust that authority are distributed with your OS. If you don’t trust your OS, ‘welp’. So this trust relationship chains up to Apple, to Google, to Microsoft, therefore you can both trust that that software came from the developer and that at least the keys that the developer used to sign it are trusted by the people who make your OS. Cool, great, sounds nice. Also, you do this check every time they push updates to that software or you download the latest version of the software, and that this particular version of the software is the thing that supposedly you're going to trust and install on your computer, not just any version. This gives us very nice guarantees about the security and provenance of the software you run on your computer. 

Well, we don't have any of that for the web. The closest thing that we have for that sort of software delivery security model is we trust the connection that we download this software over, but that's it,  and we only trust the nearest hop, because there may be many connection hops between our computer and the developer’s server, or it might be cached on an edge server. We're trusting in TLS (you are using TLS to serve your webapp, right?), and you can trust in TLS when you're downloading signed software too; but for the web,  you _only_ trust in the connection, there’s nothing else to save you if you can’t trust that connection. Since you're only trusting on the nearest hop,  if anyone can get on that connection between your computer and the webapp server,  they might serve you a different version of your web app, and you trust it because the only thing you are trusting in is the TLS connection. This is a fundamental part of why the web platform software security model is generally considered insufficient for high-security applications that need to protect sensitive data or material locally, indefinitely.

However, even in mobile apps and desktop apps, we are getting closer and closer to updating almost every time you use the app. For example, Chrome and most modern browsers are called ‘evergreen’ because they update so frequently: you are almost always on the latest version of the app every time you restart your browser. It’s almost almost guaranteed to be running a new version of the browser that was downloaded in the background and just ready to go as soon as you restarted the app. It’s similar for a lot of mobile apps: a lot of them update very frequently now, including your mobile browser. You’re downloading a new version of the software in the background, and then running new versions of the software, downloaded fresh from the internet, frequently. So there's sort of this convergence of installed apps, like mobile apps and desktop apps, that can be signed and checked, coming closer to what you do when you download a webpage: almost every time you run them, you're running fresh software (although you can check where it come from), whereas in the web browser, you’re running fresh software, that you trust _for this use and only this use_, you can’t guarantee where the software originally came from you, but just where it immediately came from (the web app server).

Okay, so why do we care? For apps like Zoom or others that want to have end-to-end encrypted data going back and forth, such designs usually require you to create an identity key. The identity key establishes ‘I am who I say I am (at least on this device)’. It's usually a signing keypair, an asymmetric pair consisting of a signing key where you sign stuff, and then a verifying key that other people can use to verify that only the person in control of this signing key can sign that thing. Then you have an ephemeral key that you can use per message, or per video call. Now the problem with building an E2E encrypted application securely via a web app is that the identity keypair has usually been long-term; so for example with Signal, when you install it on your phone, it establishes an ID keypair here and you put your public key for your long-term ID on the public Signal server, so that other people who want to communicate with you can fetch it and do a handshake with that public key, which has been signed by your long term ID. Your signing key data stays on your device forever, or until you reinstall the app. The reason this works is that you want to tie all your communications back to that public that long-term identity key via hashing and ratcheting, because you want to tie the identity you first start communicating as with all the messages that you exchange into the future. You also want to be able to detect if something happens to their keys, so you can find interceptions or compromises or MITM’s.

It's generally harder to do these things securely on the web because it's harder to protect long-term secrets in a web browser. The entire platform is ephemeral: the app is ephemeral, the software that you download is ephemeral, the communications that you're doing are ephemeral in a way.  At a software level, it's hard to keep something safe in the browser if the software you're relying on to keep it safe is changing all the time, every time you load the page. There's many, many opportunities for someone to mess with your software, because there are many, many times in normal app usage where all the software is being fetched over the internet, and implicitly trusted because the last hop connection was trusted. An adversary can pick one opportunity to MITM your connection to the server, and that's the one and only time that they update your web app  to exfiltrate your long term secret key from browser storage, and then the next time you load the page, you never see that compromised code again. But what if your actual application does not necessarily need long-term identity? 

For ephemeral audio or video calls, not long-term persistent records such as text messages, do you need a long-term identity key, especially if you are tying identity to an existing outside identity provider? If you are, the identity provider is the one that's in charge of making sure that you are who you say you are, and that you are authorized to access things and take actions as this identity. Even independent of an identity provider, your ID could just be the ‘you’ who got access to meeting data, an ID scoped just for that meaning, and we're, the meeting host, are able to identify you and your access point: a personalized meeting ID code that should be unguessable and unforgeable, handed out by the host. What if you generate your ID Keys just for that meeting? We trust that the person who got that meeting information is the person we intended to get information, because we trust that channel on first use, and then they can access the call, generate their keys, so that they can sign and verify that they are who they say they are _in the context of that call alone_, then they do all the E2EE stuff that we’re used the same as before. The host of the meeting can manage those identities per meeting: we can boot people on a per-user identity that only exists for this call, and block them from rejoining, because they should only know their per-meeting participant ID, and can’t forge their own. When the call is finished, we throw all the key material away. Becaue all the key data is thrown away at the end of the meeting, there's nothing to protect into the future, not even the software! The things you have to trust per-meeting are the software you downloaded for this one call,  and the channel that you delivered the meeting information over, at the time it is transmitted.

That design seems a lot more amenable to being implemented in a web app, because this basically boils down to TOFU (trust on first use) for the software they were running for this meeting and the channel that we deliver the per-participant meeting information over for this meeting. The trust is ephemeral, the meeting is ephemeral, the ID is ephemeral. For a lot of meetings, this is perfectly acceptable. This is also akin to our trust model of phone calls in the regular world: whoever is receiving your call is the person who has access to the callee phone number at the time of dialing, and then as soon as the call is over, you're done, and all ‘trust’ is pretty much thrown away. If someone else gets that phone number in the future, then you either trust them or you don't, _for that call_. If you want to tie these permitting identities to some other long-term ID, you can use your identity provider such as your G Suite accounts or whatever to manage accounts, and then you can attest that the ephemeral meeting ID keys are bound to the identities that must by definition be authenticated and authorized. But after the meeting is over, you can throw away those per-meeting ID keys, or if you have some integration with your ID provider, you can log them over time as a sort of key transparency, if you really care. If the meeting generates per-participant IDs that are unguessable and unforgeable, which we can do cryptographically, then we can manage those users per-meeting the way that we do anyone that's attached to long-term identity if they're being misbehaving. If you need to manage abusive people _across meetings_, that is probably where you would bring in your long-term identity provider. For most people, who are joining a call because someone emailed them a meeting link, you don't need a long-term identity, and if you don't need a long-term identity, you can do this in a browser. 

I'm not talking about browser-based crypto or the signing part or whatever because if the call is ephemeral, the web app can be trusted_just for the duration of the meeting. We already trust web apps just for the duration of whatever activity you are doing all the time  (email, for example), and a lot of our apps not on the web are moving closer to that sort of updates all the time, such as evergreen browsers, and daily updates to mobile software. I think this can be a good way to look at designing end-to-end encryption protocols and figuring out where we need long-term identity in terms of cryptographic keys, and where we don’t. If we don't need long-term identity, we don't need to protect as much secret key data in our software platform indefinitely: only need to protect it ephemerally, then we can do this sort of thing on the web, and if we can do it on the web, we can have give access to many users that desktop apps and mobile apps leave out, which I think is a win.

